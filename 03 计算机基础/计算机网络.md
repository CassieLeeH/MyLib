# 计算机网络

## TCP/IP五层协议 

TCP/IP五层协议包括：物理层，数据链路层，网络层，运输层，应用层

## OSI七层协议

![img](assets/1647149927953-7ba2a290-3d5d-425c-bdab-fdb2225647bc.png)

## 物理层

主要解决两台物理机之间的通信，通过二进制比特流的传输来实现，二进制数据表现为电流电压上的强弱，到达目的地再转化为二进制机器码。网卡、集线器工作在这一层。 

## 数据链路层

在不可靠的物理介质上提供可靠的传输，接收来自物理层的位流形式的数据，并封装成帧，传送到上一层；同样，也将来自上层的数据帧，拆装为位流形式的数据转发到物理层。这一层在物理层提供的比特流的基础上，通过差错控制、流量控制方法，使有差错的物理线路变为无差错的数据链路。提供物理地址寻址功能。交换机工作在这一层。 

相关协议：

CSMA协议：发送帧之前监听信道是否空闲，信道空闲后再发送。

CSMA/CD协议：发送帧之前监听信道是否空闲，并在发送时保持监听是否有其他信道发送，若产生碰撞则停止发送。

## 网络层

将网络地址翻译成对应的物理地址，并决定如何将数据从发送方路由到接收方，通过路由选择算法为分组通过通信子网选择最佳路径。路由器工作在这一层。 

**ARP协议**：只知道目标的IP地址，在封装成帧时需要知道目标的MAC地址，此时就需要使用ARP协议。 

通过发送一个叫做ARP请求的数据包(ARP数据包也是被包含在以太网帧中的，发送时，帧头部中的目的MAC地址填写为0xffffffff，表示在本地局域网上广播，这样该局域网的所有机器接收到这个广播帧的时候都会向协议栈递交这个帧中的数据包)，而仅当某台机器的IP地址与该ARP请求中的要询问的IP地址相同时，那台机器就才会向发送方返回一个ARP回应数据包，这个回应包中就包含了先前要询问的机器的IP地址 + MAC地址，本地主机接收到这个回应的ARP数据包后，会提取ip地址和mac地址，并记录到ARP表中。

**IP协议**：负责封装IP数据包，并进行寻址转发。**不可靠**。

![img](assets/1647149928486-e54bee2a-6edc-4d98-b4e5-7fff3c470dba.png)

## 传输层 

传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。 

TCP协议、UDP协议

## 会话层

建立会话：身份验证，权限鉴定等； 

保持会话：对该会话进行维护，在会话维持期间两者可以随时使用这条会话传输局； 

断开会话：当应用程序或应用层规定的超时时间到期后，OSI会话层才会释放这条会话。 

## 表示层 

对数据格式进行编译，对收到或发出的数据根据应用层的特征进行处理，如处理为文字、图片、音频、视频、文档等，还可以对压缩文件进行解压缩、对加密文件进行解密等。 

## 应用层

提供应用层协议，如HTTP协议，FTP协议等等，方便应用程序之间进行通信。 

# TCP

## TCP与UDP区别
![[Pasted image 20220803205431.png]]
**UDP**作为面向报文的协议，在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认，也就是说不提供可靠交付，但在即时通讯应用场景下， UDP 却是一种最有效的工作方式。
**TCP**作为面向流的协议，提供可靠的、面向连接的运输服务，并且提供点对点通信；
TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的传输服务（TCP 的可靠体现在 TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。

## 为何TCP可靠 

TCP有三次握手建立连接，四次挥手关闭连接的机制。 

除此之外还有滑动窗口和拥塞控制算法。最最关键的是还保留超时重传的机制。 

对于每份报文也存在校验，保证每份报文可靠性。 

## 为何UDP不可靠

UDP面向数据报无连接的，数据报发出去，就不保留数据备份了。 

仅仅在IP数据报头部加入校验和复用。 

UDP没有服务器和客户端的概念。 

UDP报文过长的话是交给IP切成小段，如果某段报废报文就废了。 

## TCP报文头部结构

![img](assets/1647149929011-1805ea0c-9aa3-4b17-902b-ff79250d1466.png)

## TCP三次握手过程 

![img](assets/1647149929554-78d84d0f-3189-4adc-8b7e-0873ce63f9fe.png)

1. 第一次握手：客户端发送 SYN 报文，并进入 SYN_SENT 状态，等待服务器的确认； 

2. 第二次握手：服务器收到 SYN 报文，需要给客户端发送 ACK 确认报文，同时服务器也要向客户端发送一个 SYN 报文，所以也就是向客户端发送 SYN + ACK 报文，此时服务器进入 SYN_RCVD 状态；

3. 第三次握手：客户端收到 SYN + ACK 报文，向服务器发送确认包，客户端进入 ESTABLISHED 状态。待服务器收到客户端发送的 ACK 包也会进入 ESTABLISHED 状态，完成三次握手。（**注意：第三次握手可以携带数据**）

## 为什么TCP握手需要三次，两次行不行？ 

**三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。**

第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常

第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常

第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常

所以三次握手就能确认双方收发功能都正常，缺一不可。

## TCP四次挥手过程

![img](assets/1647149929992-36babdad-1943-4161-b4c4-d7ed507844ce.png)

1. 第一次挥手。客户端发起 FIN 包（FIN = 1）,客户端进入 FIN_WAIT_1 状态。TCP 规定，即使 FIN 包不携带数据，也要消耗一个序号。 

2. 第二次挥手。服务器端收到 FIN 包，发出确认包 ACK（ack = u + 1），并带上自己的序号 seq=v，服务器端进入了 CLOSE_WAIT 状态。这个时候客户端已经没有数据要发送了，不过服务器端有数据发送的话，客户端依然需要接收。客户端接收到服务器端发送的 ACK 后，进入了 FIN_WAIT_2 状态。 

3. 第三次挥手。服务器端数据发送完毕后，向客户端发送 FIN 包（seq=w ack=u+1），半连接状态下服务器可能又发送了一些数据，假设发送 seq 为 w。服务器此时进入了 LAST_ACK 状态。 

4. 第四次挥手。客户端收到服务器的 FIN 包后，发出确认包（ACK=1，ack=w+1），此时客户端就进入了 TIME_WAIT 状态。注意此时 TCP 连接还没有释放，必须经过 2 * MSL 后，才进入 CLOSED 状态。而服务器端收到客户端的确认包 ACK 后就进入了 CLOSED 状态，可以看出服务器端结束 TCP 连接的时间要比客户端早一些。 

## 为什么TCP握手三次，挥手需要4次 

在 TCP 握手的时候，服务端发送 SYN+ACK 的包是将一个 ACK 和一个 SYN 合并到一个包中，所以减少了一次包的发送，三次完成握手。

挥手时，当服务端收到客户端的 FIN 数据包后，服务端可能还有数据没发完，不会立即close。所以服务端会先将 ACK 发过去告诉客户端我收到你的断开请求了，但请再给我一点时间，这段时间用来发送剩下的数据报文，发完之后再将 FIN 包发给客户端表示现在可以断了。之后客户端需要收到 FIN包后发送 ACK 确认断开信息给服务端。 

## 为什么四次挥手释放连接时需要等待2MSL

1. MSL 指的是报文在网络中最大生存时间。在客户端发送对服务器端的 FIN 的确认包 ACK 后，这个 ACK 包是有可能不可达的，服务器端如果收不到 ACK 的话需要重新发送 FIN 包。所以客户端发送 ACK 后需要留出 2MSL 时间（ACK 到达服务器 + 服务器发送 FIN 重传包，一来一回）等待确认服务器端确实收到了 ACK 包。也就是说客户端如果等待 2MSL 时间也没有收到服务器端的重传包 FIN，说明可以确认服务器已经收到客户端发送的 ACK。
2. 在客户端发送完最后一个 ACK 报文段后，在经过 2MSL 时间，就可以使本连接持续的时间内所产生的所有报文都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文。有些路由器会缓存 IP 数据包，如果连接重用了，那么这些延迟收到的包就有可能会跟新连接混在一起。

## TCP粘包现象 

1. **什么是粘包**？TCP粘包就是指发送方发送的若干包数据到达接收方时粘成了一包，从接收缓冲区来看，后一包数据的头紧接着前一包数据的尾。
2. **造成粘包的原因**？① **发送方**：将多次间隔较小、数据量较小的数据，合并成一个数据量大的数据块，然后进行封包。② **接收方**：TCP接收到数据包时，并不会马上交到应用层进行处理，或者说应用层并不会立即处理。实际上，TCP将接收到的数据包保存在接收缓存里，然后应用程序主动从缓存读取收到的分组。这样一来，如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。
3. **什么时候需要处理粘包？** 如果发送方发送的多组数据本来就是同一块数据的不同部分，比如说一个文件被分成多个部分发送，这时当然不需要处理粘包现象。如果多个分组毫不相干，甚至是并列关系，那么这个时候就一定要处理粘包现象了。
5. **如何处理粘包？① **发送方**：关闭这种优化算法。② **接收方**：接收方无法处理，需要上层协议处理。③ **应用层**：可以1、将数据固定格式，加入开始符和结束符。2、发送数据时将数据的长度一并发送。
6. **UDP会产生粘包吗?**  UDP则是面向消息传输的，是有保护消息边界的，接收方一次只接受一条独立的信息，所以不存在粘包问题。

## 滑动窗口和流量控制

滑动窗口是传输层进行流量控制的一种措施，接收方通过通告发送方自己的窗口大小，从而控制发送方的发送速度，防止发送方发送速度过快而导致自己被淹没。 
**TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。** 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。
如果没有滑动窗口，则服务端每次发送一个数据包后都需等待接收客户端的ACK包才能发送下一个数据包，通信效率很低。滑动窗口即无需等待确认应答即可继续发送数据的最大值。



## TCP协议的拥塞控制 

拥塞控制是防止过多的包被发送到网络中，避免出现网络负载过大，网络拥塞的情况。

-   **慢开始：** 慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd 初始值为 1，每经过一个传播轮次，cwnd 加倍。
-   **拥塞避免：** 拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送方的 cwnd 加 1。
-   **快重传与快恢复：** 在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。 　当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。


![img](assets/1648801065970-e078ee3f-e0b0-493b-b8f3-77ffcfae6ce4.png)

在TCP开始传输数据或检测到重传超时导致丢包时，执行**慢启动**策略：初始的cwnd（拥塞窗口）为1MSS，每次收到一个ACK就会使cwnd加一，通过这种方式cwnd将会呈指数增加。

当发生超时重传时，ssthresh（慢开始门限）将被设为原有cwnd的一半，当慢启动的cwnd增长到等于ssthresh时，需要执行**拥塞避免**： 每次收到ACK时，cwnd小幅增长（例如1/10MSS），呈现出线性增长趋势。

当收到连续3个重复的ACK报文（即快重传）时，执行**快速恢复**算法： ssthresh设为之前cwnd的一半，而cwnd也为原来的一半（部分实现是ssthresh+3MSS）而非从1开始，之后进入拥塞避免阶段。

![img](assets/1648801231773-ae31aaeb-bc1e-42a5-835e-0b4ca8d233c6.png)

## 快重传 

如果在超时重传定时器溢出之前，接收到连续的三个重复冗余ACK，发送端便知晓哪个报文段在传输过程中丢失了，于是重发该报文段，不需要等待超时重传定时器溢出再发送该报文。 

![img](assets/1648801194548-cfa08918-71a7-4b0f-bd22-d913fccd1b6c.png)

## 初始序列号

TCP 发送方的字节数据编号的原点，告诉对方我要开始发送数据的初始化序列号（ISN）。初始序列号如果是固定的，攻击者很容易猜出后续的确认序号，为了安全起见，避免被第三方猜到从而发送伪造的 RST 报文，因此 ISN 是动态生成的。

## 半连接队列 

TCP握手中，当服务器处于SYN_RCVD 状态，服务器会把此种状态下请求连接放在一个队列里，该队列称为半连接队列。 

## SYN攻击 

SYN攻击即利用TCP协议缺陷，通过发送大量的半连接请求，占用半连接队列，耗费CPU和内存资源。 

优化方式： 

1. 缩短SYN Timeout时间 2. 记录IP，若连续受到某个IP的重复SYN报文，从这个IP地址来的包会被一概丢弃。 


## DNS协议 DNS解析 DNS劫持

DNS协议是基于UDP的应用层协议，它的功能是根据用户输入的域名，解析出该域名对应的IP地址，从而给客户端进行访问。 可以任务是将网页域名翻译为对应的IP的一种方法。
**解析过程：**
1. 客户机发出查询请求，在本地计算机缓存查找，若没有找到，就会将请求发送给dns服务器；
2. 本地dns服务器会在自己的区域里面查找，找到即根据此记录进行解析，若没有找到，就会在本地的缓存里面查找；
3. 本地服务器没有找到客户机查询的信息，就会将此请求发送到根域名dns服务器；
4. 根域名服务器解析客户机请求的根域部分，它把包含的下一级的dns服务器的地址返回到客户机的dns服务器地址； 
5. 客户机的dns服务器根据返回的信息接着访问下一级的dns服务器； 
6. 这样递归的方法一级一级接近查询的目标，最后在有目标域名的服务器上面得到相应的IP信息； 
7. 客户机的本地的dns服务器会将查询结果返回给我们的客户机； 
8. 客户机根据得到的ip信息访问目标主机，完成解析过程。

DNS劫持指攻击者篡改结果，使用户对域名的解析IP变成了另一个IP。

# HTTP

## 浏览器中输入一个网址后，具体发生了什么

1. 首先，在浏览器地址栏中输入url，先解析url，检测url地址是否合法；
2. 浏览器先查看浏览器缓存系统缓存-路由器缓存，如果缓存中有，会直接在屏幕中显示页面内容。若没有，则跳到第三步操作。

- 浏览器缓存:浏览器会记录DNS一段时间，因此，只是第一个地方解析DNS请求;
- 操作系统缓存:如果在浏览器缓存中不包含这个记录，则会使系统调用操作系统，获取操作系统的记录(保存最近的DNS查询缓存)
- 路由器缓存:如果上述两个步骤均不能成功获取DNS记录，继续搜索路由器缓存；
- ISP缓存:若上述均失败，继续向ISP搜索。

1. 在发送http请求前，需要域名解析(DNS解析)，解析获取相应的IP地址；
2. 浏览器向服务器发起tcp连接，与浏览器建立tcp三次握手；
3. 握手成功后，浏览器向服务器发送http请求，请求数据包；
4. 服务器处理收到的请求，将数据返回至浏览器；
5. 浏览器收到HTTP响应；
6. 浏览器解码响应，如果响应可以缓存，则存入缓存；
7. 浏览器发送请求获取嵌入在HTML中的资源(html，css，javascript，图片，音乐……)，对于未知类型，会弹出对话框；
8. 浏览器发送异步请求；
9. 页面全部渲染结束。

## HTTP协议 

http协议是超文本传输协议。它是基于TCP协议的应用层传输协议，即客户端和服务端进行数据传输的一种规则。该协议本身HTTP 是一种**无状态**的协议。 

##  cookie与session 

HTTP是一种无状态协议，本身是不保存信息的，但是我们使用中有保存用户信息的需求。

Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。
HTTP 协议本身是无状态的，为了使其能处理更加复杂的逻辑，HTTP/1.1 **引入 Cookie 来保存状态信息**。 

Cookie技术通过在请求和响应报文中写入Cookie信息来控制客户端的状态。Cookie会根据从服务端发送的响应报文内的Set-Cookie的首部字段信息，通知客户端保存Cookie。当下次客户端再往该服务器发送请求时，会在请求报文中加入Cookie值后发送出去。

Cookie是由服务端产生的，再发送给客户端保存，当客户端再次访问的时候，服务器可根据cookie辨识客户端是哪个，以此可以做个性化推送，免账号密码登录等等。 

session用于**标记特定客户端信息，存在在服务器的一个文件**里。 

一般客户端带Cookie对服务器进行访问，可通过cookie中的session id从整个session中查询到服务器记录的关于客户端的信息。 

session被用于记录一个用户在网站上的一些行为、一些状态，可以理解为一个上下文，这些内容被**存储在服务器**中，往往通过Cookie进行实现：session的运行基于sessionID，服务端在收到客户端的请求报文后，将sessionID存在cookie中发给客户端，客户端在后续的请求报文头部都加上sessionID，服务端通过这种方式识别客户端。

## http状态码

2xx Success（成功状态码）
-   **200 OK** ：请求被成功处理。比如我们发送一个查询用户数据的HTTP 请求到服务端，服务端正确返回了用户数据。这个是我们平时最常见的一个 HTTP 状态码。
-   **201 Created** ：请求被成功处理并且在服务端创建了一个新的资源。比如我们通过 POST 请求创建一个新的用户。
-   **202 Accepted** ：服务端已经接收到了请求，但是还未处理。
-   **204 No Content** ： 服务端已经成功处理了请求，但是没有返回任何内容。

3xx Redirection（重定向状态码）
-   **301 Moved Permanently** ： 资源被永久重定向了。比如你的网站的网址更换了。
-   **302 Found** ：资源被临时重定向了。比如你的网站的某些资源被暂时转移到另外一个网址。

4xx Client Error（客户端错误状态码）
-   **400 Bad Request** ： 发送的HTTP请求存在问题。比如请求参数不合法、请求方法错误。
-   **401 Unauthorized** ： 未认证却请求需要认证之后才能访问的资源。
-   **403 Forbidden** ：直接拒绝HTTP请求，不处理。一般用来针对非法请求。
-   **404 Not Found** ： 你请求的资源未在服务端找到。比如你请求某个用户的信息，服务端并没有找到指定的用户。
-   **409 Conflict** ： 表示请求的资源与服务端当前的存状态在冲突，请求无法被处理。

5xx Server Error（服务端错误状态码）
-   **500 Internal Server Error** ： 服务端出问题了（通常是服务端出Bug了）。比如你服务端处理请求的时候突然抛出异常，但是异常并为在服务端被正确处理。
-   **502 Bad Gateway** ：我们的网关将请求转发到服务端，但是服务端返回的却是一个错误的响应。

## 转发和重定向的区别 

转发是服务器行为,客户端只请求一次。客户浏览器发送http请求 -> web服务器接受此请求->调用内部的一个方法在容器内部完成请求处理和转发动作->将目标资源发送给客户；在这里，转发的路径必须是同一个web容器下的url，其不能转向到其他的web路径上去，中间传递的是自己的容器内的request。 ![img](assets/1647149935261-9f365481-683c-45c5-9e3e-c506e42ad5ee.png)



重定向是客户浏览器发送http请求-> web服务器接受后发送302状态码响应及对应新的location给客户浏览器->客户浏览器发现是302响应，则自动再发送一个新的http请求，请求url是新的location地址->服务器根据此请求寻找资源并发送给客户。 

## https的连接过程 

\1. 浏览器将支持的加密算法信息发给服务器 

\2. 服务器选择一套浏览器支持的加密算法，以证书的形式回发给浏览器 

\3. 客户端(SSL/TLS)解析证书验证证书合法性，生成对称加密的密钥，我们将该密钥称之为client key，即客户端密钥，用服务器的公钥对客户端密钥进行非对称加密。 

\4. 客户端会发起HTTPS中的第二个HTTP请求，将加密之后的客户端对称密钥发送给服务器 

\5. 服务器接收到客户端发来的密文之后，会用自己的私钥对其进行非对称解密，解密之后的明文就是 客户端密钥，然后用客户端密钥对数据进行对称加密，这样数据就变成了密文。 

\6. 服务器将加密后的密文发送给客户端；

\7. 客户端收到服务器发送来的密文，用客户端密钥对其进行对称解密，得到服务器发送的数据。这样HTTPS中的第二个HTTP请求结束，整个HTTPS传输完成。

## REST API

REST API全称为表述性状态转移（Representational State Transfer，REST）即利用HTTP中get、post、put、delete以及其他的HTTP方法构成REST中数据资源的增删改查操作： 

Get：指定资源请求数据，刷新无害，Get请求的数据会附加到URL中，传输数据的大小受到url的限制。 

Post：向指定资源提交要被处理的数据。刷新会使数据会被重复提交。post在发送数据前会先将请求头发送给服务器进行确认，然后才真正发送数据。 

Put规定默认为更新某一资源，和Post一样，一般该操作会对服务器资源进行改变 

Delete规定默认为删除某一资源，和Post一样，一般该操作会对服务器资源进行改变 

## Get方法参数有大小限制吗 

一般HTTP协议里并不限制参数大小限制。但一般由于get请求是直接附加到地址栏里面的，由于浏览器地址栏有长度限制，因此使GET请求在浏览器实现层面上看会有长度限制。 


## http请求包含了什么

包含：请求方法字段、URL字段、HTTP协议版本 

产生请求的浏览器类型，请求数据，主机地址。

## 简述TLS/SSL, HTTP, HTTPS的关系 

SSL全称为Secure Sockets Layer即安全套接层，其继任为TLSTransport Layer Security传输层安全协议，均用于在传输层为数据通讯提供安全支持。 

可以将HTTPS协议简单理解为HTTP协议＋TLS/SSL 

## http与https的区别 

https = http +SSL

http所有传输的内容都是明文，并且客户端和服务器端都无法验证对方的身份。 

https具有安全性的ssl加密传输协议，加密采用对称加密， 

https协议需要到ca申请证书，一般免费证书很少，需要交费。

## SSL

SSL全称为Secure Sockets Layer即安全套接层，其继任为TLSTransport Layer Security传输层安全协议，均用于在传输层为数据通讯提供安全支持。 

**公开密钥和私有密钥**：公开密钥可以让任何人获取，私有密钥仅能自己知道。具体实现：发送密文的一方使用对方公开密钥加密的信息发送给接收方，接收方收到后使用自己的私有密钥进行解密，提取出其中的信息。（这种方式存在一定的漏洞，无法证明获取到的公开密钥就是货真价实的密钥，有可能在传输过程中被替换了。因此存在第三方机构进行CA认证）。

**共享密钥**：加密和解密使用同一个密钥的方式成为共享密钥。

SSL采取混合加密机制：先使用公开密钥和私有密钥使通信双方获得共享密钥，再使用共享密钥进行通信。

![img](assets/1647149939539-39aebf21-d523-45bf-b446-6923d32950f8.png)

## http1.0 

1.无法复用连接：每一个请求都是一个单独的连接，做不到连接的复用 。每次请求都需要新建立一个TCP连接。

2.队头阻塞：规定了请求头和请求尾，响应头和响应尾（get post）。下一次请求需要等待上一次请求的响应到达后才能发出，若一个请求的响应一直无法到达，则会导致后续请求都被阻塞。 

## 简述http1.1的改进 

1. **长连接**：HTTP/1.1增加了一个Connection字段，通过设置Keep-alive（默认已设置）可以保持连接不断开，避免了每次客户端与服务器请求都要重复建立释放TCP连接，提高了网络的利用率。如果客户端想关闭HTTP连接，可以在请求头中携带Connection:false来告知服务器关闭请求。
2. **支持请求管道化**（pipelining）。基于HTTP/1.1的长连接，使得请求管线化成为可能。一个请求无需等到收到上一个请求的响应时才能发出，客户端能一次发送多个请求。需要注意的是，服务器必须按照客户端请求的先后顺序依次回送相应的结果，以保证客户端能够区分出每次请求的响应内容，也就是说，不允许同时存在两个并行的响应。**虽然HTTP/1.1支持管道化，但是服务器也必须进行逐个响应的送回，这个是很大的一个缺陷。实际上，现阶段的浏览器厂商采取了另外一种做法，它允许我们打开多个TCP的会话来实现并行。**
3. 服务端无法主动push 


## HTTP短连接与长连接区别

HTTP中的长连接短连接指HTTP底层TCP的连接。 

短连接： 客户端与服务器进行一次HTTP连接操作，就进行一次TCP连接，连接结束TCP关闭连接。 

长连接：如果HTTP头部带有参数keep-alive，即开启长连接网页完成打开后，底层用于传输数据的TCP 连接不会直接关闭，会根据服务器设置的保持时间保持连接，保持时间过后连接关闭。 

## 简述http2.0的改进 

提出多路复用。多路复用前，文件时串行传输的，请求a文件，b文件只能等待，并且连接数过多。引入多路复用，a文件b文件可以同时传输。 

引入了二进制数据帧。其中帧对数据进行顺序标识，有了序列id，服务器就可以进行并行传输数据。 

## http2.0（基于SPDY实现）

HTTP1.1虽然支持了长连接和管道，但因为服务器必须按顺序发送响应客户端才能正确解析，导致浏览器只有建立多个TCP连接（通常是6个）才能实现真正的并行，消耗了很多资源。

![img](assets/1647149935834-28b43f5e-8f3e-4eca-a8bf-2e1f780df720.png)

HTTP2.0的目标：回到单个TCP连接，解决队头阻塞。

HTTP2.0 将请求和响应数据分割为更小的帧，并且它们采用二进制编码。HTTP2.0在每个块前面放置一个所谓的数据帧（DATA frame）。这些数据帧主要包含两个关键的元数据。第一：下面的块属于哪个资源。每个资源的“字节流（bytestream）”都被分配了一个唯一的数字，即流id（stream id）。第二：块的大小是多少。协议还有许多其他帧类型，例如头部帧（HEADERS frame），这样甚至可以将头（headers）从它们的实际响应数据中分离出来。

![img](assets/1647149936359-405a9d85-1092-4e7a-abb7-b3cbdee4f4c8.png)

因此，通过“framing”单个消息，HTTP/2 比 HTTP/1.1 更加灵活。它允许在单个 TCP 连接上通过交错排列块来多路传输多个资源。它还解决了第一个资源缓慢时的队头阻塞问题：而不必等待查询数据库生成的index.html，服务器可以在等待index.html时开始发送其他资源。

![img](assets/1647149936933-9fd1029b-b994-4033-9d2c-27c2343227f0.png)

## http2.0的缺陷

由于TCP队头阻塞的存在，http2.0在使用多路复用时的效率可能不一定高于6个TCP并行连接的http1.1。具体原因如下：

![img](assets/1647149937427-3004d3c2-a09b-4c5c-9f28-f5138a9feba6.png)

如果 TCP 数据包2在网络中丢失，但数据包1和数据包3已经到达，会发生什么情况？请记住，TCP只知道它需要按顺序传递数据。因此，它知道数据包1的内容可以安全使用，并将这些内容传递给浏览器。然而，它发现数据包1中的字节和数据包3中的字节（放数据包2 的地方）之间存在间隙，因此还不能将数据包3传递给浏览器。TCP 将数据包3保存在其接收缓冲区（receive buffer）中，直到它接收到数据包2的重传副本（这至少需要往返服务器一次），之后它可以按照正确的顺序将这两个数据包都传递给浏览器。换个说法：丢失的数据包2 队头阻塞了数据包3。

https://zhuanlan.zhihu.com/p/330300133

## http3.0（QUIC协议）

由于TCP队头阻塞，提出了基于UDP的http3.0协议。

![img](assets/1647149937854-55cc1f1a-822e-49e4-90dd-7d696921eecc.png)

![img](assets/1647149938452-2f1a0bfd-c99b-435c-9d87-3727ae01250d.png)

与 HTTP/2 的数据帧（DATA frames）非常相似，QUIC 的流帧（STREAM frames）分别跟踪每个流的字节范围。像以前一样，让我们考虑一下如果 QUIC 数据包2丢失，而 1 和 3 到达会发生什么。与 TCP 类似，数据包1中流1（stream 1）的数据可以直接传递到浏览器。然而，对于数据包3，QUIC 可以比 TCP 更聪明。它查看流1的字节范围，发现这个流帧（STREAM frame）完全遵循流id 1的第一个流帧 STREAM frame（字节 450 跟在字节 449 之后，因此数据中没有字节间隙）。它可以立即将这些数据提供给浏览器进行处理。然而，对于流id 2，QUIC确实看到了一个缺口（它还没有接收到字节0-299，这些字节在丢失的 QUIC 数据包2中）。它将保存该流帧（STREAM frame），直到 QUIC 数据包2的重传（retransmission）到达。

但在实际应用中，QUIC是否真的能加速网络传输呢？

QUIC在传输大小差异很大的两个数据包时具有优势：12121211111111111，这样能使得2尽早交付到上层，但也存在如下情况：

![img](assets/1647149938867-5a2fc11e-1d7a-4fbd-8232-b819991c440a.png)

