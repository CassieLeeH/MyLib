# 数据结构八股文

## 栈

栈是一种线性表，其限制只能在表尾进行插入或删除操作。由于该特性又称为后进先出的线性表。

## 队列

队列是一种先进先出的线性表。其限制只能在线性表的一端进行插入，而在另一端删除元素。

## 树的理解 

数据结构树是一种由有限节点组成的层次关系的集合。其特点如下： 

\1. 每个节点有零个或多个子节点； 

\2. 只有一个节点没有父节点，该节点称为根节点； 

\3. 除根节点外，每个节点有且只有一个父节点； 

## 满二叉树

一个二叉树，如果每一个层的结点数都达到最大值，则这个二叉树就是满二叉树。

## 完全二叉树 

一棵深度为k的有n个结点的二叉树，对树中的结点按从上至下、从左到右的顺序进行编号，如果编号为i （1≤i≤n）的结点与满二叉树中编号为i的结点在二叉树中的位置相同，则这棵二叉树称为完全二叉树。 

## 二叉树的前中后序遍历算法

前序遍历：若二叉树为空树，则执行空逻辑，否则： 

\1. 访问根节点

\2. 递归前序遍历左子树 

\3. 递归前序遍历右子树 

中序遍历：若二叉树为空树，则执行空逻辑，否则： 

\1. 递归中序遍历左子树 

\2. 访问根节点 

\3. 递归中序遍历右子树 

后序遍历：若二叉树为空树，则执行空逻辑，否则： 

\1. 递归后序遍历左子树 

\2. 递归后序遍历右子树 

\3. 访问根节点

## 二叉查找树 

\1. 二叉查找树的左子树若不为空，则左子树上所有结点的值均小于它的根结点的值； 

\2. 二叉查找树的右子树若不为空，则右子树上所有结点的值均大于它的根结点的值； 

\3. 二叉查找树的左、右子树也分别为二叉查找树； 

\4. 没有键值相等的结点。

## **AVL（平衡查找树）树** 

AVL树是一种改进版的搜索二叉树，其引入平衡因子（左子支高度与右子支高度之差的绝对值），通过旋转使其尽量保持平衡。

任何一个节点的左子支高度与右子支高度之差的绝对值不超过1。  

## **红黑树** 

红黑树本身是有2-3树发展而来，红黑树是保持黑平衡的二叉树，其查找会比AVL树慢一点，添加和删除元素会比AVL树快一点。增删改查统计性能上讲，红黑树更优。 

红黑树主要特征是在每个节点上增加一个属性表示节点颜色，可以红色或黑色。红黑树和 AVL 树类似， 都是在进行插入和删除时通过旋转保持自身平衡，从而获得较高的查找性能。红黑树保证从根节点到叶 尾的最长路径不超过最短路径的 2 倍，所以最差时间复杂度是 O(logn)。红黑树通过重新着色和左右旋转，更加高效地完成了插入和删除之后的自平衡调整。

## B树和B+树

**B树**属于多叉树又名平衡多路查找树（查找路径不只两个），数据库索引技术里大量使用者B树和B+树的数据结构。

（1）排序方式：所有节点关键字是按递增次序排列，并遵循左小右大原则；

（2）子节点数：非叶节点的子节点数>1，且<=M ，且M>=2，空树除外（注：M阶代表一个树节点最多有多少个查找路径，M=M路,当M=2则是2叉树,M=3则是3叉）；

（3）关键字数：枝节点的关键字数量大于等于ceil(m/2)-1个且小于等于M-1个（注：ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2);

（4）所有叶子节点均在同一层、叶子节点除了包含了关键字和关键字记录的指针外也有指向其子节点的指针只不过其指针地址都为null对应下图最后一层节点的空格子;

**b+树：**

b+树是B树的一个升级版，相对于B树来说B+树更充分的利用了节点的空间，让查询速度更加稳定，其速度完全接近于二分法查找。

规则

（1）B+跟B树不同B+树的非叶子节点不保存关键字记录的指针，只进行数据索引，这样使得B+树每个非叶子节点所能保存的关键字大大增加；

（2）B+树叶子节点保存了父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到。所以每次数据查询的次数都一样；

（3）B+树叶子节点的关键字从小到大有序排列，左边结尾数据都会保存右边节点开始数据的指针。

（4）非叶子节点的子节点数=关键字数（来源百度百科）（根据各种资料 这里有两种算法的实现方式，另一种为非叶节点的关键字数=子节点数-1（来源维基百科)，虽然他们数据排列结构不一样，但其原理还是一样的Mysql 的B+树是用第一种方式实现）;

**对比：**

1、B+树的层级更少：相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快；

2、B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;

3、B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。

4、B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。

B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。

## **解决Hash冲突的方法** 

开放定址法：当发生哈希冲突时，如果哈希表未被装满，那么可以把这个值存放到冲突位置中的下一个空位置中去

链地址法：对相同的哈希地址，设置一个单链表，单链表内放的都是哈希冲突元素。 

## **稳定排序和非稳定排序的区别** 

稳定排序：排序前后两个相等的数相对位置不变，则算法稳定 

非稳定排序：排序前后两个相等的数相对位置发生了变化，则算法不稳定 

## **稳定排序算法有哪些** 

插入排序、冒泡排序、归并排序 

## **不稳定排序算法有哪些** 

希尔排序、直接选择排序、堆排序、快速排序 

![img](assets/1647149901567-0fca0717-83f1-48bf-87cf-bd9a93ff7e5f.png)



排序算法详解：

https://www.cnblogs.com/onepixel/articles/7674659.html



## 排序算法的选择

数据量规模较⼩，考虑直接插⼊或直接选择。当元素分布有序时直接插⼊将⼤⼤减少⽐较和移动记录的 

次数，如果不要求稳定性，可以使⽤直接选择，效率略⾼于直接插⼊。

数据量规模中等，选择希尔排序。

数据量规模较⼤，考虑堆排序（元素分布接近正序或逆序）、快速排序（元素分布随机）和归并排序

（稳定性）。

⼀般不使⽤冒泡。

## **插入排序** 

插入排序：每一趟将一个待排序记录按其关键字的大小插入到已排好序的一组记录的适当位置上，直到所有待排序记录全部插入为止。 

排序算法稳定。时间复杂度 O(n²)，空间复杂度 O(1)。 

```go
func InsertionSort(nums []int) []int {
	n := len(nums)
	preindex, current := 0, 0
	for i := 0; i < n; i++ {
		preindex = i - 1
		current = nums[i]
		for preindex >= 0 && nums[preindex] > current {
			nums[preindex+1] = nums[preindex]
			preindex--
		}
		nums[preindex+1] = current
	}
	return nums
}
```

## 选择排序（Selection Sort）

选择排序(Selection-sort)是一种简单直观的排序算法。它的工作原理：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 

```plsql
func selectionSort(nums []int) []int {
	n := len(nums)
	mimIndex, temp := 0, 0
	for i := 0; i < n; i++ {
		mimIndex = i
		for j := i + 1; j < n; j++ {
			if nums[j] < nums[mimIndex] {
				mimIndex = j
			}
		}
		temp = nums[i]
		nums[i] = nums[mimIndex]
		nums[mimIndex] = temp
	}
	return nums
}
```

## **希尔排序** 

希尔排序：把记录按下标的一定增量分组，对每组进行直接插入排序，每次排序后减小增量，当增量减至 1 时排序完毕。

排序算法不稳定。时间复杂度 O(nlogn)，空间复杂度 O(1)。 

```go
func ShellSort(nums []int) []int {
	n := len(nums)
	//d 为步长
	for d := n / 2; d > 0; d = d / 2 {
		for i := d; i < n; i++ {
			j := i
			current := nums[i]
			//如果后面小于前面,交换前后
			for j-d >= 0 && current < nums[j-d] {
				nums[j] = nums[j-d]
				j = j - d
			}
			nums[j] = current
		}
	}
	return nums
}
```

## **直接选择排序** 

直接选择排序：每次在未排序序列中找到最小元素，和未排序序列的第一个元素交换位置，再在剩余未排序序列中重复该操作直到所有元素排序完毕。 

排序算法不稳定。时间复杂度 O(n²)，空间复杂度 O(1)。 

## 堆排序 

堆排序：将待排序数组看作一个树状数组，建立一个二叉树堆。通过对这种数据结构进行每个元素的插入，完成排序工作。 

排序算法不稳定，时间复杂度 O(nlogn)，空间复杂度 O(1)。 

## **冒泡排序** 

冒泡排序：比较相邻的元素，如果第一个比第二个大就进行交换，对每一对相邻元素做同样的工作。 

排序算法稳定，时间复杂度 O(n²)，空间复杂度 O(1)。 

```plsql
func bubbleSort(nums []int) []int {
	n := len(nums)
	for i := 0; i < n-1; i++ {
		for j := 0; j < n-1-i; j++ {
			if nums[j] > nums[j+1] {
				temp := nums[j+1]
				nums[j+1] = nums[j]
				nums[j] = temp
			}
		}
	}
	return nums
}
```

## 快速排序 

快速排序：随机选择一个基准元素，通过一趟排序将要排序的数据分割成独立的两部分，一部分全部小于等于基准元素，一部分全部大于等于基准元素，再按此方法递归对这两部分数据进行快速排序。 

排序算法不稳定，时间复杂度 O(nlogn)，空间复杂度 O(logn)。 

```plsql
func quickSort(nums []int, low int, high int) []int {
    mid := getIndex(nums, low, high)
    if low < high {
        quickSort(nums, low, mid-1)
    }
    if high > low {
        quickSort(nums, mid+1, high)
    }
    return nums
}
func getIndex(nums []int, low int, high int) int {
    p := nums[low]
    for low < high {
        for low < high && p <= nums[high] {
            high--
        }
        nums[low] = nums[high]
        for low < high && p > nums[low] {
            low++
        }
        nums[high] = nums[low]
    }
    nums[low] = p
    return low
}
```

## 归并排序 

归并排序：将待排序序列分成两部分，然后对两部分分别递归排序，最后进行合并。 

排序算法稳定，时间复杂度都为 O(nlogn)，空间复杂度为 O(n)。 

```go
func MergeSort(nums []int, low int, high int) {
	if low >= high {
		return
	}
	mid := (low + high) / 2
	//左半段
	MergeSort(nums, low, mid)
	//右半段
	MergeSort(nums, mid+1, high)
	Merge(nums, low, mid, high)
}

func Merge(nums []int, low int, mid int, high int) {
	var tempNums []int
	var s1, s2 = low, mid + 1
	for s1 <= mid && s2 <= high {
		//将s1和s2指向的数中较小的那个存进tempNums中
		if nums[s1] > nums[s2] {
			tempNums = append(tempNums, nums[s2])
			s2++
		} else {
			tempNums = append(tempNums, nums[s1])
			s1++
		}
	}
	//如果有一半没读完,就把没读完的那段一直存到临时数组后方
	if s1 <= mid {
		tempNums = append(tempNums, nums[s1:mid+1]...)
	}
	if s2 <= high {
		tempNums = append(tempNums, nums[s2:high+1]...)
	}
	//将临时数组中整理好的部分存回原数组
	for pos, item := range tempNums {
		nums[low+pos] = item
	}
}
```

## 图 

图是由顶点集合和顶点之间的边集合组成的一种数据结构，分为有向图和无向图。 

有向图：边具有方向性 

无向图：边不具有方向性 

## 邻接矩阵 

用一个二维数组存放图顶点间关系的数据，这个二维数组称为邻接矩阵。 

对于无向图，邻接矩阵是对称矩阵。 

## 邻接表

邻接表是通过链表表示图连接关系的一种方。对于表头结点所对应的顶点存在相邻顶点，则把相邻顶点依次存放于表头结点所指向的单向链表中。 

## 图的深度优先搜索DFS 

将图中每个顶点的访问标志设为 FALSE, 之后搜索图中每个顶点，如果未被访问，则以该顶点V0为起始点出发，访问此顶点，然后依次从V0的各个未被访问的邻接点出发深度优先搜索遍历图，直至图中所有和V0有路径相通的顶点都被访问到。 

## 图的广度优先搜索BFS

从图中的某个顶点V0出发，并在访问此顶点之后依次访问V0的所有未被访问过的邻接点，之后按这些顶点被访问的先后次序依次访问它们的邻接点，直至图中所有和V0有路径相通的顶点都被访问到。 

## 最小生成树和其对应的算法 

对于有 n 个结点的原图，生成原图的极小连通子图，其包含原图中的所有 n 个结点，并且有保持图连通的最少的边。 

普里姆算法：取图中任意一个顶点 v 作为生成树的根，之后往生成树上添加新的顶点 w。在添加的顶点w 和已经在生成树上的顶点v 之间必定存在一条边，并且该边的权值在所有连通顶点 v 和 w 之间的边中取值最小。之后继续往生成树上添加顶点，直至生成树上含有 n-1 个顶点为止。 

克鲁斯卡尔算法：先构造一个只含 n 个顶点的子图 SG，然后从权值最小的边开始，若它的添加不使SG 中产生回路，则在 SG 上加上这条边，如此重复，直至加上 n-1 条边为止。 

## 最短路径算法 

Dijkstral算法为求解一个点到其余各点最小路径的方法，其算法为： 

假设我们求解的是顶点v到其余各个点的最短距离。n次循环至n个顶点全部遍历： 

\1. 从权值数组中找到权值最小的，标记该边端点k 

\2. 打印该路径及权值 

\3. 如果存在经过顶点k到顶点i的边比v->i的权值小 

\4. 更新权值数组及对应路径 

## 堆

堆是一种完全二叉树形式，其可分为最大值堆和最小值堆。 

最大值堆：子节点均小于父节点，根节点是树中最大的节点。 

最小值堆：子节点均大于父节点，根节点是树中最小的节点。 

堆相关：

https://gitee.com/SnailClimb/JavaGuide/blob/main/docs/cs-basics/data-structure/heap.md

## set 

Set是一种集合。集合中的对象不按特定的方式排序，并且没有重复对象。 
